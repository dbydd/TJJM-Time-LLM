{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'datasets\\\\datasets_data\\\\collected\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取与预处理\n",
    "xlsx = []\n",
    "csv = []\n",
    "\n",
    "#ignored: ecodata, air_condition\n",
    "\n",
    "def read(path,date_key='时间',date_format = None,operations=None,dropsubset=None):\n",
    "    sheet = pd.read_csv(path,index_col= date_key,parse_dates=[date_key],date_format=date_format)\n",
    "    sheet.rename(columns={date_key:'date'},inplace=True)\n",
    "    sheet.dropna(subset=dropsubset)\n",
    "    if operations is not None:\n",
    "        sheet = operations(sheet)\n",
    "    sheet = sheet.resample('YE').mean()\n",
    "    return sheet\n",
    "\n",
    "# xlsx.append[([pd.read_excel(os.path.join(path,'carbon_emission.xlsx'))],'emission vector')]\n",
    "\n",
    "csv.append(read(os.path.join(path,'air_pollution_events.csv'),operations=lambda x: x.filter(regex='大气污染事故次数:年')))\n",
    "csv.append(read(os.path.join(path,'citylize.csv')))\n",
    "csv.append(read(os.path.join(path,'comsume.csv'),'时间?',operations=lambda x : x.filter(regex='支出')))\n",
    "csv.append(read(os.path.join(path,'controllable_income.csv'),'时间'))\n",
    "csv.append(read(os.path.join(path,'energy_investment.csv'),operations= lambda x: x.filter(regex='固定资产投资额(不含农户):能源工业:上海市:年')))\n",
    "csv.append(read(os.path.join(path,'energy_structure.csv'),'时间?',operations=lambda x: x.filter(['能源生产总量构成:水电、核电、风电:年?','一次能源生产量:年?'])))\n",
    "# csv.append(read(os.path.join(path,'medic_insurance.csv'),operations=lambda sheet: sheet.resample('YE').mean())) # 数据太少，影响整体质量，不使用\n",
    "csv.append(read(os.path.join(path,'thick_cause_death.csv'),'时间?',operations= lambda x: x.filter(regex='(农村呼吸系统疾病粗死亡率_)|(城市呼吸系统疾病粗死亡率_)')))\n",
    "csv.append(read(os.path.join(path,'work_time.csv'),operations=lambda sheet: sheet.resample('YE').mean()))\n",
    "csv.append(read(r'D:\\huge_program_project\\TJJM-Time-LLM\\datasets\\datasets_data\\collected\\processed\\gdp\\上海市_gdp_yearly_sum.csv',date_key='年份',operations=lambda x: x.rename(columns={'总量（亿元）':'gdp'})))\n",
    "csv.append(read(r'D:\\huge_program_project\\TJJM-Time-LLM\\datasets\\datasets_data\\collected\\processed\\co2\\上海_emission.csv',date_key='year',operations=lambda x:x.rename(columns={'emission':'co2_emission'})))\n",
    "csv.append(read(r'D:\\huge_program_project\\TJJM-Time-LLM\\datasets\\datasets_data\\collected\\processed\\aqi\\上海市_yearly_aircondition.csv',date_key='年份',operations=lambda x:x.rename(columns={'AQI':'当年平均空气质量指数'})))\n",
    "\n",
    "\n",
    "csvs = pd.concat(csv,axis=1)\n",
    "\n",
    "# regex = '.*Road$'\n",
    "# mask = csvs.apply(\n",
    "#     lambda col: col.str.contains(regex, regex=True, na=False)\n",
    "# ).any(axis=1) & csvs.notnull().all(axis=1)\n",
    "\n",
    "# csvs = csvs.loc[mask]\n",
    "rem = csvs.columns.difference(['date'])\n",
    "\n",
    "for col in rem:\n",
    "    csvs[col] = csvs[col].interpolate(method='spline', order=1)\n",
    "    csvs[col] = csvs[col].dropna()\n",
    "    \n",
    "# 找到全为非空值的行\n",
    "mask = csvs.notnull().all(axis=1)\n",
    "\n",
    "# 将布尔掩码转换为int\n",
    "mask = mask.astype(int)\n",
    "\n",
    "# 计算差异和累积和以生成组ID\n",
    "group_ids = mask.diff().ne(0).cumsum()\n",
    "\n",
    "# 找到最长的组\n",
    "longest_group = group_ids.groupby(group_ids).size().idxmax()\n",
    "\n",
    "# 切片原始DataFrame以获取该组\n",
    "result = csvs.loc[group_ids != longest_group]\n",
    "result.index.name= 'date'\n",
    "\n",
    "result.rename(columns={\n",
    "    'date': '日期', \n",
    "    '大气污染事故次数:年': '大气污染事故次数',\n",
    "    '乡村人口数:年': '乡村人口数',\n",
    "    '城镇人口数:年': '城镇人口数',\n",
    "    '城乡居民比例': '城乡人口比',\n",
    "    '农村家庭平均每人年消费性支出:年?': '农村人均消费支出',\n",
    "    '城镇居民人均消费性支出:年?': '城镇人均消费支出',\n",
    "    '居民可支配收入': '可支配收入',\n",
    "    '能源生产总量构成:水电、核电、风电:年?': '清洁能源占比',\n",
    "    '一次能源生产量:年?': '一次能源生产量', \n",
    "    '城市呼吸系统疾病粗死亡率_当期值_年?': '城市呼吸系统疾病死亡率',\n",
    "    '农村呼吸系统疾病粗死亡率_当期值_年?': '农村呼吸系统疾病死亡率',\n",
    "    '就业人员周平均工作时间:当期值:月': '周均工作时间',\n",
    "    'gdp': 'GDP',\n",
    "    'co2_emission': 'CO2排放量',\n",
    "    '当年平均空气质量指数': '空气质量指数'\n",
    "}, inplace=True)\n",
    "\n",
    "#神秘代码，但就是能用\n",
    "\n",
    "result.to_csv(os.path.join(path,'processed','summarize.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "import joblib\n",
    "# 读取summarize.csv\n",
    "df = pd.read_csv(r'datasets\\datasets_data\\collected\\processed\\summarize.csv',index_col='date',parse_dates=['date'])\n",
    "# 将'date'列转换为datetime类型\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 检查数据质量\n",
    "print(\"数据形状:\", df.shape)\n",
    "# print(\"数据类型:\\n\", df.dtypes)\n",
    "# print(\"缺失值检查:\\n\", df.isnull().sum())\n",
    "\n",
    "# 假设整理后的DataFrame变量名为df\n",
    "# 选择需要标准化的列\n",
    "columns = ['大气污染事故次数', '乡村人口数', '城镇人口数', '农村人均消费支出', \n",
    "                    '城镇人均消费支出', '可支配收入', '清洁能源占比', '一次能源生产量',\n",
    "                    '城市呼吸系统疾病死亡率', '农村呼吸系统疾病死亡率', '周均工作时间', \n",
    "                    'GDP', 'CO2排放量', '空气质量指数']\n",
    "\n",
    "# 初始化StandardScaler\n",
    "scaler = StandardScaler().fit(df[columns])\n",
    "\n",
    "# 对选定的列进行标准化\n",
    "df[columns] = scaler.transform(df[columns])\n",
    "\n",
    "# print(\"预处理后的数据:\\n\", df.head())\n",
    "df.to_csv(os.path.join(path,'processed',\"data_preprocessed.csv\"))  # 保存预处理后的数据\n",
    "joblib.dump(scaler, os.path.join(path,'processed',\"scalar.pkl\")) #保存缩放因子方便后续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分析\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = ['SimHei']  # 使用中文字体\n",
    "\n",
    "# 读取预处理后的数据\n",
    "df = pd.read_csv(os.path.join(path,'processed',\"data_preprocessed.csv\"), index_col='date', parse_dates=['date'])\n",
    "\n",
    "# Granger因果检验\n",
    "maxlag = 2  # 设置最大时滞\n",
    "test_results = pd.DataFrame(np.zeros((len(columns), len(columns))),\n",
    "                            index=columns, columns=columns)\n",
    "for cause in columns:\n",
    "    for effect in columns:\n",
    "        if cause != effect:\n",
    "            test = grangercausalitytests(list(df[[cause, effect]].dropna().values), maxlag=maxlag, verbose=False)\n",
    "            p_values = [test[i+1][0]['ssr_ftest'][1] for i in range(maxlag)]\n",
    "            min_p_value = np.min(p_values)\n",
    "            test_results.loc[cause, effect] = min_p_value\n",
    "\n",
    "# 交叉相关分析\n",
    "lags = range(1, 11)  # 设置时滞范围\n",
    "cross_corr = pd.DataFrame(index=columns, columns=columns)\n",
    "for cause in columns:\n",
    "    for effect in columns:\n",
    "        if cause != effect:\n",
    "            cross_corr.loc[cause, effect] = df[cause].shift(1).corr(df[effect])\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 20))\n",
    "sns.heatmap(test_results, ax=ax1, cmap='YlGnBu', annot=False,fmt='.3f')\n",
    "ax1.set_title('Granger Causality')\n",
    "sns.heatmap(cross_corr.astype(float), ax=ax2, cmap='YlOrRd', annot=False,fmt='.3f')\n",
    "ax2.set_title('Cross Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Solver didnt converge, see SolverResult.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Value\n",
      "DoF              98.000000\n",
      "DoF Baseline    119.000000\n",
      "chi2                   inf\n",
      "chi2 p-value      0.000000\n",
      "chi2 Baseline  1114.995893\n",
      "CFI                   -inf\n",
      "GFI                   -inf\n",
      "AGFI                  -inf\n",
      "NFI                   -inf\n",
      "TLI                   -inf\n",
      "RMSEA                  inf\n",
      "AIC                   -inf\n",
      "BIC                   -inf\n",
      "LogLik                 inf\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# 输出结果\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# print(model.inspect())\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(semopy\u001b[38;5;241m.\u001b[39mcalc_stats(model)\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 81\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43msemopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marticle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfigures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msem_model.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# 计算成本效益\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost_benefit\u001b[39m(policy_cost, health_benefit, discount_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\plot.py:68\u001b[0m, in \u001b[0;36msemplot\u001b[1;34m(mod, filename, inspection, plot_covs, plot_exos, images, engine, latshape, plot_ests, std_ests, show)\u001b[0m\n\u001b[0;32m     66\u001b[0m     plot_ests \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     inspection \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minspect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstd_est\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_ests\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\model.py:574\u001b[0m, in \u001b[0;36mModel.inspect\u001b[1;34m(self, mode, what, information, std_est, se_robust)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03mGet fancy view of model parameters estimates.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspect\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minspect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstd_est\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mse_robust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mse_robust\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\inspector.py:48\u001b[0m, in \u001b[0;36minspect\u001b[1;34m(model, mode, what, information, std_est, se_robust)\u001b[0m\n\u001b[0;32m     46\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minspect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_est\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_est\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mse_robust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mse_robust\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmx\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inspect_matrices(model, what\u001b[38;5;241m=\u001b[39mwhat)\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\inspector.py:203\u001b[0m, in \u001b[0;36minspect_list\u001b[1;34m(model, information, std_est, se_robust, index_names)\u001b[0m\n\u001b[0;32m    201\u001b[0m         std_full[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m information \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     se \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_se\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mse_robust\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     zscores \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mcalc_zvals(model, std_errors\u001b[38;5;241m=\u001b[39mse)\n\u001b[0;32m    205\u001b[0m     pvals \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mcalc_pvals(model, z_scores\u001b[38;5;241m=\u001b[39mzscores)\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\stats.py:498\u001b[0m, in \u001b[0;36mcalc_se\u001b[1;34m(model, information, robust)\u001b[0m\n\u001b[0;32m    495\u001b[0m                 mult \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m information \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 498\u001b[0m     mx_inf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_fim\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumdifftools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient, Hessian\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\model.py:1767\u001b[0m, in \u001b[0;36mModel.calc_fim\u001b[1;34m(self, inverse)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_fim\u001b[39m(\u001b[38;5;28mself\u001b[39m, inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;124;03m    Calculate Fisher Information Matrix.\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \n\u001b[0;32m   1766\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1767\u001b[0m     sigma, (m, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1768\u001b[0m     sigma_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_sigma_grad(m, c)\n\u001b[0;32m   1769\u001b[0m     inv_sigma \u001b[38;5;241m=\u001b[39m chol_inv(sigma)\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\semopy\\model.py:1407\u001b[0m, in \u001b[0;36mModel.calc_sigma\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;124;03mCalculate model-implied covariance matrix.\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1404\u001b[0m \n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m beta, lamb, psi, theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatrices[:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m-> 1407\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1408\u001b[0m m \u001b[38;5;241m=\u001b[39m lamb \u001b[38;5;241m@\u001b[39m c\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m \u001b[38;5;241m@\u001b[39m psi \u001b[38;5;241m@\u001b[39m m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m theta, (m, c)\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\19920\\scoop\\apps\\anaconda3\\current\\App\\envs\\ai_models\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import semopy\n",
    "from semopy import Model\n",
    "\n",
    "# 读取数据\n",
    "# data = pd.read_csv('data_preprocessed.csv', index_col='date', parse_dates=True)\n",
    "data = pd.read_csv(os.path.join(path, 'processed', 'data_preprocessed.csv'), index_col='date', parse_dates=True)\n",
    "\n",
    "\n",
    "# # 添加潜变量\n",
    "# model.add_lv(\"Health\")\n",
    "# model.add_lv(\"Environment\")\n",
    "# model.add_lv(\"Economy\")\n",
    "# model.add_lv(\"Policy\")\n",
    "\n",
    "# # 添加观测变量\n",
    "# model.add_ov(\"大气污染事故次数\", latent=\"Environment\")\n",
    "# model.add_ov(\"乡村人口数\", latent=\"Economy\") \n",
    "# model.add_ov(\"城镇人口数\", latent=\"Economy\")\n",
    "# model.add_ov(\"城乡人口比\", latent=\"Economy\")\n",
    "# model.add_ov(\"农村人均消费支出\", latent=\"Economy\")\n",
    "# model.add_ov(\"城镇人均消费支出\", latent=\"Economy\") \n",
    "# model.add_ov(\"可支配收入\", latent=\"Economy\")\n",
    "# model.add_ov(\"清洁能源占比\", latent=\"Environment\")\n",
    "# model.add_ov(\"一次能源生产量\", latent=\"Environment\")\n",
    "# model.add_ov(\"城市呼吸系统疾病死亡率\", latent=\"Health\")\n",
    "# model.add_ov(\"农村呼吸系统疾病死亡率\", latent=\"Health\")\n",
    "# model.add_ov(\"周均工作时间\", latent=\"Economy\")\n",
    "# model.add_ov(\"GDP\", latent=\"Economy\") \n",
    "# model.add_ov(\"CO2排放量\", latent=\"Environment\")\n",
    "# model.add_ov(\"空气质量指数\", latent=\"Environment\")\n",
    "\n",
    "# # 添加路径\n",
    "# model.add_path(\"Environment\", \"Health\")  \n",
    "# model.add_path(\"Economy\", \"Health\")\n",
    "# model.add_path(\"Policy\", \"Environment\")\n",
    "# model.add_path(\"Policy\", \"Economy\")\n",
    "# model.add_path(\"Economy\", \"Environment\")\n",
    "\n",
    "model = \"\"\"\n",
    "     # 潜变量\n",
    "      Health =~ 城市呼吸系统疾病死亡率 + 农村呼吸系统疾病死亡率\n",
    "      Environment =~ 大气污染事故次数 + 清洁能源占比 + 一次能源生产量 + CO2排放量 + 空气质量指数\n",
    "      Economy =~ 乡村人口数 + 城镇人口数 + 城乡人口比 + 农村人均消费支出 + 城镇人均消费支出 + 可支配收入 + 周均工作时间 + GDP\n",
    "      Policy =~ 1*Policy\n",
    "    \n",
    "      # 观测变量\n",
    "      大气污染事故次数 ~~ NA*大气污染事故次数\n",
    "      乡村人口数 ~~ NA*乡村人口数\n",
    "      城镇人口数 ~~ NA*城镇人口数\n",
    "      城乡人口比 ~~ NA*城乡人口比\n",
    "      农村人均消费支出 ~~ NA*农村人均消费支出\n",
    "      城镇人均消费支出 ~~ NA*城镇人均消费支出\n",
    "      可支配收入 ~~ NA*可支配收入\n",
    "      清洁能源占比 ~~ NA*清洁能源占比\n",
    "      一次能源生产量 ~~ NA*一次能源生产量\n",
    "      城市呼吸系统疾病死亡率 ~~ NA*城市呼吸系统疾病死亡率\n",
    "      农村呼吸系统疾病死亡率 ~~ NA*农村呼吸系统疾病死亡率\n",
    "      周均工作时间 ~~ NA*周均工作时间\n",
    "      GDP ~~ NA*GDP\n",
    "      CO2排放量 ~~ NA*CO2排放量\n",
    "      空气质量指数 ~~ NA*空气质量指数\n",
    "    \n",
    "      # 路径关系\n",
    "      Health ~ Environment + Economy\n",
    "      Environment ~ Policy + Economy\n",
    "      Economy ~ Policy\n",
    "\"\"\"\n",
    "\n",
    "# 定义模型\n",
    "model = Model(model)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(data)\n",
    "\n",
    "# 输出结果\n",
    "# print(model.inspect())\n",
    "\n",
    "print(semopy.calc_stats(model).T)\n",
    "g = semopy.semplot(model, os.path.join(\"article\",\"figures\",\"sem_model.png\"))\n",
    "\n",
    "# 计算成本效益\n",
    "def cost_benefit(policy_cost, health_benefit, discount_rate=0.05, time_horizon=20):\n",
    "    net_benefit = 0\n",
    "    for t in range(time_horizon):\n",
    "        net_benefit += (health_benefit - policy_cost) / (1 + discount_rate)**t\n",
    "    return net_benefit\n",
    "\n",
    "policy_cost = 1000  # 假设的政策成本\n",
    "health_benefit = model.predict(data, \"Health\", policy=1) - model.predict(data, \"Health\", policy=0)\n",
    "health_benefit = health_benefit.mean() * 10000  # 假设每个单位对应1万元的健康效益\n",
    "\n",
    "net_benefit = cost_benefit(policy_cost, health_benefit)\n",
    "print(f\"净效益: {net_benefit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO optimize\n",
    "import os\n",
    "import pandas as pd\n",
    "import semopy\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = ['SimHei']  # 使用中文字体\n",
    "\n",
    "# 读取预处理后的数据\n",
    "data = pd.read_csv(os.path.join(path, 'processed', 'data_preprocessed.csv'), index_col='date', parse_dates=['date'])\n",
    "\n",
    "# 定义潜变量和观测变量\n",
    "latent_vars = ['个人层面', '微观层面', '中观层面', '宏观层面']\n",
    "\n",
    "observed_vars = {\n",
    "    '个人层面': ['个人收入', '个人健康'],\n",
    "    '微观层面': ['环境污染', '能源利用'],\n",
    "    '中观层面': ['环保投资', '技术水平'],\n",
    "    '宏观层面': ['经济发展', '人口结构']\n",
    "}\n",
    "\n",
    "# 创建标准化数据\n",
    "scaled_data = pd.DataFrame(index=data.index)\n",
    "for lv, ovs in observed_vars.items():\n",
    "    for ov in ovs:\n",
    "        scaled_data[ov] = (data[ov] - data[ov].mean()) / data[ov].std()\n",
    "\n",
    "# 定义lavaan模型语法\n",
    "model_syntax = \"\"\"\n",
    "    # 潜变量定义\n",
    "    个人层面 =~ 个人收入 + 个人健康\n",
    "    微观层面 =~ 环境污染 + 能源利用  \n",
    "    中观层面 =~ 环保投资 + 技术水平\n",
    "    宏观层面 =~ 经济发展 + 人口结构\n",
    "    \n",
    "    # 潜变量关系\n",
    "    微观层面 ~ 个人层面\n",
    "    中观层面 ~ 微观层面\n",
    "    宏观层面 ~ 中观层面\n",
    "\"\"\"\n",
    "\n",
    "# 创建模型\n",
    "model = semopy.Model(model_syntax)\n",
    "\n",
    "# 拟合模型参数\n",
    "fitted_model = model.fit(scaled_data,obj=\"DWLS\")\n",
    "\n",
    "print(semopy.calc_stats(model).T)\n",
    "g = semopy.semplot(model, os.path.join(\"article\",\"figures\",\"sem_model.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
